arch: "default"

images:
  # Try to use a local image first.
  - location: "~/Downloads/hirsute-server-cloudimg-amd64.img"
    arch: "x86_64"
  - location: "~/Downloads/hirsute-server-cloudimg-arm64.img"
    arch: "aarch64"

  # Download the file from the internet when the local file is missing.
  # Hint: run `limactl prune` to invalidate the "current" cache
  - location: "https://cloud-images.ubuntu.com/hirsute/current/hirsute-server-cloudimg-amd64.img"
    arch: "x86_64"
  - location: "https://cloud-images.ubuntu.com/hirsute/current/hirsute-server-cloudimg-arm64.img"
    arch: "aarch64"

mounts:
  - location: "~"
    writable: false
  - location: "/tmp/lima"
    writable: true

ssh:
  localPort: 60060
  loadDotSSHPubKeys: true

containerd:
  system: true
  user: false

provision:
  - mode: system
    script: |
      #!/bin/sh
      PROVISIONED_FILE=/etc/.node-provisioned
      if [ -f "$PROVISIONED_FILE" ]; then
          echo "node provisioned; skipping"
          exit 0
      fi
      ln -sf /usr/local/bin/nerdctl /usr/local/bin/docker

      cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
      br_netfilter
      EOF
      modprobe br_netfilter

      cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
      net.bridge.bridge-nf-call-ip6tables = 1
      net.bridge.bridge-nf-call-iptables = 1
      net.ipv4.ip_forward = 1
      EOF
      sysctl --system
      # k8s
      apt-get update
      apt-get install -y apt-transport-https ca-certificates curl
      curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
      echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
      apt-get update
      apt-get install -y kubelet kubeadm kubectl
      apt-mark hold kubelet kubeadm kubectl

      # deploy k8s
      cat <<EOF | sudo tee /tmp/kubeadm-config.yaml
      kind: ClusterConfiguration
      apiVersion: kubeadm.k8s.io/v1beta3
      kubernetesVersion: v1.22.1
      apiServer:
        certSANs:
          - "127.0.0.1"
          - "192.168.5.15"
          - "10.96.0.1"
      networking:
        podSubnet: "10.244.0.0/16"
      ---
      kind: KubeletConfiguration
      apiVersion: kubelet.config.k8s.io/v1beta1
      cgroupDriver: cgroupfs
      EOF
      kubeadm init --config /tmp/kubeadm-config.yaml
      # wait until ready
      while true; do curl -o /dev/null -s -k https://192.168.5.15:6443 ; if [ $? -eq 0 ]; then break ; fi ; done
      export KUBECONFIG=/etc/kubernetes/admin.conf
      # taint master
      kubectl taint nodes --all node-role.kubernetes.io/master-
      # install cni
      kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
      touch $PROVISIONED_FILE

  - mode: user
    script: |
      echo "alias k=kubectl" >> ~/.bashrc
      mkdir -p $HOME/.kube
      sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
      sudo chown $(id -u):$(id -g) $HOME/.kube/config
      cp $HOME/.kube/config /tmp/lima/$(hostname)-config
      sed -i 's/192\.168\.5\.15/127\.0\.0\.1/g' /tmp/lima/$(hostname)-config

probes:
  - mode: readiness
    description: kubernetes ready
    script: |
      #!/bin/bash
      set -eux -o pipefail
      if ! timeout 300s bash -c "until kubectl get nodes; do sleep 5; done"; then
        echo >&2 "node not ready"
        exit 1
      fi
    hint: |
      Kubernetes node was not ready in the expected time.  See "/var/log/cloud-init-output.log" in the guest for more info.

firmware:
  legacyBIOS: false

video:
  display: "none"

network:
  vde:

